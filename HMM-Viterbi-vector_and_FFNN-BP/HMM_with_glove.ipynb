{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93__D8_YFq0-"
      },
      "source": [
        "### Library used in this program "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_p8esScM5QI",
        "outputId": "72c6fdab-979e-4b34-f8c2-a2edd8eef818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import brown\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import norm\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKA8bP-PFmJM"
      },
      "source": [
        "### DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3kq_uhjNMyS"
      },
      "outputs": [],
      "source": [
        "# splitting the corpus into two for now\n",
        "train_corpus, test_corpus = train_test_split(brown.tagged_sents(tagset='universal'), test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lySD9yYLNbUO"
      },
      "outputs": [],
      "source": [
        "class storage:\n",
        "  #creating dataset for storing the computed data.\n",
        "  def __init__(self):\n",
        "    self.id = 0\n",
        "    self.index2tag = dict()\n",
        "    self.value2id = dict()\n",
        "    self.values = set()\n",
        "\n",
        "  def get_length():\n",
        "    return self.id\n",
        "  \n",
        "  def insert(self, value):\n",
        "    self.index2tag[self.id] = value\n",
        "    self.value2id[value] = self.id\n",
        "    self.values.add(value)\n",
        "    self.id += 1\n",
        "    \n",
        "  def retrive(self, key, method ='id'):\n",
        "    if method == 'id':\n",
        "      return self.index2tag[key]\n",
        "    elif key in self.values:\n",
        "      return self.value2id[key]\n",
        "    else: \n",
        "      return None\n",
        "\n",
        "# val variable for hadling some cases\n",
        "alpha = 0.000001 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1HTo-QOFfzo"
      },
      "source": [
        "### HMM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdYxp5cUODIJ"
      },
      "outputs": [],
      "source": [
        "def get_word(train_corpus):\n",
        "  words = storage()\n",
        "\n",
        "  for sent in train_corpus:\n",
        "    for word,tag in sent:\n",
        "      if words.retrive(word.lower(), 'temp') == None:\n",
        "        words.insert(word.lower())\n",
        "  return words\n",
        "\n",
        "def get_tag():\n",
        "  tag_list = set([tag for words,tag in brown.tagged_words(tagset='universal')])\n",
        "  tags = storage()\n",
        "\n",
        "  for tag in tag_list:\n",
        "    if tags.retrive(tag, 'temp') == None:\n",
        "      tags.insert(tag)\n",
        "  return tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faiCHDx2UQRk"
      },
      "outputs": [],
      "source": [
        "words = get_word(train_corpus)\n",
        "tags = get_tag()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vWjeZh-Dxec",
        "outputId": "a4999b0f-cc13-491b-b4da-e87251ef766f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHTDg9ZZU6LH",
        "outputId": "eaf5a614-9d10-4a12-f4c8-721c69874527"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "glove_file = datapath('/content/drive/MyDrive/Glove/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5DbUIydVLl5"
      },
      "outputs": [],
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If97I3IWODoo"
      },
      "outputs": [],
      "source": [
        "temp = list(words.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAgU1-pktHLS"
      },
      "outputs": [],
      "source": [
        "word_vec_list = []\n",
        "word_vec_list = [model[word] for word in temp if word in model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veUoqLxxYgnx",
        "outputId": "08228c31-f80c-45d7-e214-5ea442efb8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37194\n",
            "45025\n"
          ]
        }
      ],
      "source": [
        "print(len(word_vec_list))\n",
        "print(len(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBdwc7NAUyGF"
      },
      "outputs": [],
      "source": [
        "def get_hmm_matrix(train_corpus, words, tags, alpha):\n",
        "  transmission_matrix = np.zeros([tags.id,tags.id])\n",
        "  emission_matrix = np.zeros([tags.id,words.id])\n",
        "  tags_prob = np.zeros([tags.id])\n",
        "\n",
        "  for sent in tqdm(train_corpus):\n",
        "    for index in range(len(sent)):\n",
        "      word = sent[index][0]\n",
        "      tag = sent[index][1]\n",
        "\n",
        "      word_index = words.retrive(word.lower(), 'temp')\n",
        "      tag_index = tags.retrive(tag,'temp')\n",
        "\n",
        "      tags_prob[tag_index] +=1\n",
        "      emission_matrix[tag_index,word_index] +=1\n",
        "      if index != len(sent) - 1:\n",
        "        next_tag = tags.retrive(sent[index + 1][1], 'temp')\n",
        "        transmission_matrix[tag_index,next_tag] +=1\n",
        "\n",
        "  transmission_matrix = np.divide((transmission_matrix+ alpha), (np.reshape(tags_prob,[-1,1])+(alpha*12)))\n",
        "  emission_matrix = np.divide((emission_matrix+alpha), (np.reshape(tags_prob,[-1,1])+ alpha*12))\n",
        "  tags_prob = np.divide(tags_prob, np.sum(tags_prob))\n",
        "\n",
        "\n",
        "  transmission_matrix[transmission_matrix == 0] = alpha\n",
        "  emission_matrix[emission_matrix == 0] =alpha\n",
        "  tags_prob[tags_prob == 0] = alpha\n",
        "\n",
        "  return transmission_matrix,emission_matrix,tags_prob\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW_pdcDbw7dA",
        "outputId": "6097e893-d7ea-4ec1-f8a6-f74f7b4dd205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45872/45872 [00:03<00:00, 13723.98it/s]\n"
          ]
        }
      ],
      "source": [
        "transmission_matrix,emission_matrix,tags_prob = get_hmm_matrix(train_corpus,words,tags,alpha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G67tOI7-L9hY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW-sKKr7NbUw"
      },
      "outputs": [],
      "source": [
        "# Viterbi algorithm\n",
        "\n",
        "def get_pos(sent_list, transmission_matrix, emission_matrix, tags_prob, words,word_vec_list, tags,model, alpha = 0.000001):\n",
        "  if len(sent_list) == 0:\n",
        "    return []\n",
        "  A = np.array(word_vec_list)\n",
        "  seq_score_matrix = np.zeros([tags.id, len(sent_list)])\n",
        "  back_pointer = np.zeros([tags.id, len(sent_list)])\n",
        "  # First step in viterbi Intialization\n",
        "  word_id = words.retrive(sent_list[0].lower(), 'temp')\n",
        "  for i in range(tags.id):\n",
        "    if word_id == None:\n",
        "      # if sent_list[0].lower() in model:\n",
        "      #   B = np.array(model[sent_list[0].lower()])\n",
        "      #   cosine = np.dot(A,B)/(norm(A, axis=1)*norm(B))\n",
        "      #   seq_score_matrix[i,0] = tags_prob[i] * emission_matrix[i,np.argmax(cosine)]\n",
        "      # else:\n",
        "        seq_score_matrix[i,0] = tags_prob[i] * alpha\n",
        "    else:\n",
        "      seq_score_matrix[i,0] = tags_prob[i] * emission_matrix[i,word_id]\n",
        "    back_pointer[i,0] = 0\n",
        "\n",
        "  # Second step is Iteration\n",
        "  for p in range(len(sent_list)):\n",
        "    if p!= 0:\n",
        "      for i in range(tags.id):\n",
        "        word_id = words.retrive(sent_list[p].lower(), 'temp')\n",
        "        transmission_vector = np.multiply(seq_score_matrix[:, p-1], transmission_matrix[:, i])\n",
        "        tag_max_arg = np.argmax(transmission_vector)\n",
        "        # print(len(transmission_vector\n",
        "        back_pointer[i,p] = tag_max_arg\n",
        "        # print(back_pointer)\n",
        "\n",
        "        if word_id == None:\n",
        "          if sent_list[0].lower() in model:\n",
        "            B = np.array(model[sent_list[0].lower()])\n",
        "            cosine = np.dot(A,B)/(norm(A, axis=1)*norm(B))\n",
        "            seq_score_matrix[i,p] = transmission_vector[tag_max_arg] * emission_matrix[i,np.argmax(cosine)]\n",
        "          else:\n",
        "            seq_score_matrix[i,p] = transmission_vector[tag_max_arg] * alpha\n",
        "        else:\n",
        "          seq_score_matrix[i,p] = transmission_vector[tag_max_arg] * emission_matrix[i,word_id]\n",
        "          \n",
        "  # Third Step is Sequence Identification\n",
        "  tag_index = np.zeros([len(sent_list)])\n",
        "  tag_index[-1] = np.argmax(seq_score_matrix[:, len(sent_list)-1])\n",
        "  # print(back_pointer)\n",
        "  # print(tag_index)\n",
        "  for i in reversed(range(len(sent_list)-1)):\n",
        "    tag_index[i] = back_pointer[int(tag_index[i+1]), int(i+1)]\n",
        "  # print(tag_index)\n",
        "  return [tags.retrive(index, 'id') for index in tag_index]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLNxxSj8Fqj0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "sente = 'jack came back from work and he reeks of fish.'\n",
        "sente = re.findall( r'\\w+|[^\\s\\w]+', sente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nVasQ2CptkX",
        "outputId": "6d2bb755-01d3-47dc-ad81-312b2d5ce1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERB\n"
          ]
        }
      ],
      "source": [
        "for sent in train_corpus:\n",
        "    for word,tag in sent:\n",
        "      if word == 'reeked':\n",
        "        print(tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX7a3hMGlP1Y",
        "outputId": "be07a984-1e3d-4ecb-fb0a-8be6d4cda03b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('reeked', 0.7333507537841797),\n",
              " ('reeking', 0.656512975692749),\n",
              " ('dullness', 0.6038519144058228),\n",
              " ('smacks', 0.5738084316253662),\n",
              " ('phoniness', 0.5679745674133301),\n",
              " ('tastelessness', 0.5672473311424255),\n",
              " ('superficiality', 0.5661382675170898),\n",
              " ('weirdness', 0.5652622580528259),\n",
              " ('meanness', 0.5648483633995056),\n",
              " ('bespeaks', 0.563983678817749)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.most_similar('reeks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkuZYpcnDG-",
        "outputId": "73926f1d-76df-4b73-e9e2-7b53f59a39bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39385"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "words.value2id['reeked']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tvBetJPuUvu3",
        "outputId": "0ab2badc-5cc6-435d-9902-7600a5f1623f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jack'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "sente[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFc3dAhoi_-o",
        "outputId": "ed1ee1b4-107d-4be6-9676-672d6de5de96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NOUN', 'VERB', 'ADV', 'ADP', 'NOUN', 'CONJ', 'PRON', 'NOUN', 'ADP', 'NOUN', '.']\n"
          ]
        }
      ],
      "source": [
        "print(get_pos(sente, transmission_matrix,emission_matrix,tags_prob, words,word_vec_list, tags,model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGlRqscwWClj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsWMTdxvmJF6"
      },
      "outputs": [],
      "source": [
        "def prediction(test_corpus, transmission_matrix, emission_matrix, tags_prob, words, tags, alpha):\n",
        "  confusion_matrix = np.zeros([tags.id,tags.id], dtype=np.int32)\n",
        "\n",
        "  for test_sent in tqdm(test_corpus):\n",
        "    test_tag = [item[1] for item in test_sent]\n",
        "    test_token = [item[0] for item in test_sent]\n",
        "\n",
        "    predicted_tag = get_pos(test_token,transmission_matrix, emission_matrix, tags_prob, words,word_vec_list, tags,model, alpha)\n",
        "    for (predicted, test) in zip(predicted_tag, test_tag):\n",
        "      confusion_matrix[tags.retrive(predicted,'temp'), tags.retrive(test,'temp')] += 1\n",
        "  \n",
        "  return confusion_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUvVw-wpLJeU"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA2aFuBqz7s9"
      },
      "outputs": [],
      "source": [
        "def cross_validation():\n",
        "  tags = get_tag()\n",
        "  confusion_matrix = np.zeros([tags.id,tags.id], dtype=np.int32)\n",
        "  dataset = np.array(brown.tagged_sents(tagset='universal'))\n",
        "  kfold = KFold(n_splits=5,shuffle=True)\n",
        "  kfold.get_n_splits(dataset)\n",
        "\n",
        "  for train, test in kfold.split(dataset):\n",
        "    train_courpus = dataset[train]\n",
        "    test_courpus = dataset[test]\n",
        "    print(\"Train Data Size: \",len(train))\n",
        "    print(\"Test Data Size: \",len(test))\n",
        "    words = get_word(train_corpus)\n",
        "    transmission_matrix,emission_matrix,tags_prob = get_hmm_matrix(train_corpus,words,tags,alpha)\n",
        "    confusion_matrix += prediction(test_corpus, transmission_matrix, emission_matrix, tags_prob, words, tags, alpha)\n",
        "\n",
        "  return confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8lHbT9VOQWx",
        "outputId": "1b3e9e2d-4a2c-4ef5-d620-e930fba70e9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data Size:  45872\n",
            "Test Data Size:  11468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45872/45872 [00:03<00:00, 14365.76it/s]\n",
            " 27%|██▋       | 3150/11468 [03:58<10:46, 12.86it/s]"
          ]
        }
      ],
      "source": [
        "confusion_matrix = cross_validation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnW51fJqOhui"
      },
      "source": [
        "### overall accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tVchSdzOgLA"
      },
      "outputs": [],
      "source": [
        "#overall accuracy\n",
        "total_examples = np.sum(confusion_matrix)\n",
        "correct_predictions = np.trace(confusion_matrix)\n",
        "print('The overall accuracy of the hmm model is:', correct_predictions * 100 / total_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KMFETN-Olfe"
      },
      "outputs": [],
      "source": [
        "# plotting the heat map\n",
        "plt.figure(figsize = (20, 20))\n",
        "tag_list = [tags.retrive(i, 'id') for i in range(tags.id)]\n",
        "confusion_figure = sns.heatmap(confusion_matrix, annot=True, xticklabels=tag_list, yticklabels=tag_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW23AcmlQMWT"
      },
      "outputs": [],
      "source": [
        "per_pos_dict = {'tag': [], 'precision': [], 'recall': [], 'f1-score': []}\n",
        "for tag_id in range(tags.id):\n",
        "  per_pos_dict['precision'].append(confusion_matrix[tag_id, tag_id] / np.sum(confusion_matrix[tag_id, :]))\n",
        "  per_pos_dict['recall'].append(confusion_matrix[tag_id, tag_id] / np.sum(confusion_matrix[:, tag_id]))\n",
        "  per_pos_dict['tag'].append(tags.retrive(tag_id, 'id'))\n",
        "  per_pos_dict['f1-score'].append(2 * per_pos_dict['precision'][tag_id] * per_pos_dict['recall'][tag_id] / (per_pos_dict['recall'][tag_id] + per_pos_dict['precision'][tag_id]))\n",
        "per_pos_df = pd.DataFrame(per_pos_dict)\n",
        "per_pos_df.to_csv('hmm_per_pos_accuracy.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTvJhHLkyQ8K"
      },
      "outputs": [],
      "source": [
        "print(per_pos_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvNtTWeiRAx6"
      },
      "outputs": [],
      "source": [
        "Overall_precision = np.sum(per_pos_df['precision'])/12\n",
        "Overall_recall = np.sum(per_pos_df['recall'])/12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMbQArqIk8iw"
      },
      "outputs": [],
      "source": [
        "f1_score = 2 * Overall_precision * Overall_recall / ( Overall_precision + Overall_recall)\n",
        "f_half_score = 1.25 * Overall_precision * Overall_recall / ( (0.25*Overall_precision) + Overall_recall)\n",
        "f2_score = 5 * Overall_precision * Overall_recall / ( (4*Overall_precision) + Overall_recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD9ZrXJl0VKH"
      },
      "source": [
        "### Fbeta = ((1 + beta^2) * Precision * Recall) / (beta^2 * Precision + Recall)\n",
        "\n",
        "*   F0.5-Measure (beta=0.5): More weight on precision, less weight on recall.\n",
        "\n",
        "*   F2-Measure (beta=2.0): Less weight on precision, more weight on recall\n",
        "\n",
        "*   F1-Measure (beta=1.0): Balance the weight on precision and recall.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfN2T0erxJgl"
      },
      "outputs": [],
      "source": [
        "print(\"Precision: \",Overall_precision)\n",
        "print(\"Recall: \",Overall_recall)\n",
        "print(\"F1_score: \",f1_score)\n",
        "print(\"F0.5_score: \",f_half_score)\n",
        "print(\"F2_score: \",f2_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv_DI55dxoi9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}